{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "double Deep q  chrome dino",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunsaiAlaparthi/reinforcment_learning/blob/main/double_Deep_q_chrome_dino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxfPgzhfR6JC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gym\n",
        "from collections import namedtuple\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJraon3NSVI"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn5dGzzwNV8B"
      },
      "source": [
        "pip install gym-chrome-dino"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNTa1EjFTXLW"
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract**\n",
        "\n",
        "I wrote this double deep q algoritham to train an RL agent to play the chrome dino game. I was initially using the normal DQN algorithm , but the training was very unstable , SO later I switched to Double Deep q networks. The entire pipeline is I have an image encoder which is a basic cnn, where I bundle 4 frames 1 current and 3 previous and encode it using CNN , after encoding the vector will be fed into the q network as a state , and the network assigns q values, for each state action pairs. The algorithms uses replay buffer to store the experience/episodes , state, action , reward and next state values. I have then random sampled experiences and trained the network again so that the agent doesn't forget past experiences, there's also priority replay buffers where episodes which have high q values - reward differences will be sampled first. As I am using double deep q networks, I am using 2 networks policy and a target network.\n",
        "\n",
        "I am also using epsilon - greedy strategy which is mostly common for RL algorithms which pushed the agents to explore more increasing the randomness in taking actions, once it's trained on all possibilties , we make the model exploit more with occasional exploration.\n",
        "\n",
        "Training :\n",
        "\n",
        "For each experience in the batch, the target Q-value is computed using the Double Q-Learning approach:\n",
        "\n",
        "The policy network is used to determine the action taking the argmax Q-value for the next state.\n",
        "\n",
        "The target network then evaluates the Q-value for that action to compute the target.\n",
        "\n",
        "The Q-Network is updated by minimizing the difference between the predicted Q-values and the computed target Q-values.\n",
        "\n",
        "The target network updates periodically using soft update, this is the main advantage which keeps the target stable.\n",
        "\n",
        "This is the demo that i got:\n",
        "https://www.youtube.com/watch?v=3nfH1JJUL0g"
      ],
      "metadata": {
        "id": "8NsgDDA6A0sl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBOIC1WyN6SP"
      },
      "source": [
        "#Install the chrome dino packages for running the gym simulator\n",
        "import gym_chrome_dino\n",
        "from gym_chrome_dino.utils.wrappers import make_dino\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldFqJU95TgYg"
      },
      "source": [
        "num_epochs=4\n",
        "alpha=1e-4\n",
        "batch_size=512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7kw-4cbj0Ed"
      },
      "source": [
        "#Creating a named tuple for storing the experience\n",
        "\n",
        "Experience = namedtuple('Experience',('state','action','next_state','reward','done'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYW1OYWtkJDW"
      },
      "source": [
        "\n",
        "#This is the class that I am using for replaymemory, which has push which is called after every episode, and sample for creating mini\n",
        "#batches to train later on, This is fine as the q learning algorithms are off policy. can provide is just for a flag to check if there\n",
        "#are enough experiences.\n",
        "\n",
        "class replaymemory():\n",
        "  def __init__(self,capacity):\n",
        "    self.capacity=capacity\n",
        "    self.memory=[]\n",
        "    self.push_count=0\n",
        "\n",
        "  def push(self,experience):\n",
        "    if(self.push_count>self.capacity):\n",
        "      self.memory[self.push_count%self.capacity]=experience\n",
        "    else:\n",
        "      self.memory.append(experience)\n",
        "    self.push_count+=1\n",
        "\n",
        "\n",
        "  def sample(self,batch_size):\n",
        "    e=random.sample(self.memory,batch_size)\n",
        "    #print(type(e1.state))\n",
        "    states=torch.tensor([e1.state for e1 in e]).to(device)\n",
        "    actions=torch.tensor([e1.action for e1 in e]).to(device)\n",
        "    next=torch.tensor([e1.next_state for e1 in e]).to(device)\n",
        "    rewards = torch.tensor(([e1.reward for e1 in e])).to(device)\n",
        "    dones = torch.tensor([e1.done for e1 in e])\n",
        "\n",
        "    #states=states.view(64,1,80,160)\n",
        "    return states.float(),actions,next,rewards,dones\n",
        "\n",
        "  def can_provide(self,batch_size):\n",
        "    return len(self.memory)>=batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zF_N2_Eqa4r"
      },
      "source": [
        "#I am just using this to create a 4 framed array, so that I can concatenate the latest 4 batched frames always\n",
        "\n",
        "class cstate():\n",
        "  def __init__(self,size):\n",
        "    self.size=size\n",
        "    self.states=[]\n",
        "    self.push_count=0\n",
        "  def push(self,state):\n",
        "    if self.push_count<self.size:\n",
        "      self.states.append(state)\n",
        "      self.push_count=self.push_count+1\n",
        "    else:\n",
        "      self.states.pop(0)\n",
        "      self.states.append(state)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qXV53iJoTi7"
      },
      "source": [
        "#This is the class for epsilon strategy , where with greedy which is used for exploitation , I am just using argmax to get the action\n",
        "# with the highest q value, where as for get_action depends on the epsilon value, here I am decaying it exponentially, so\n",
        "# in the inital phases it favours more of exploration and as episodes go on it favours more of exploitation.\n",
        "\n",
        "class eps_strat():\n",
        "  def __init__(self,num_actions,start,decay,end,device):\n",
        "    self.cur_step=0\n",
        "    self.num=num_actions\n",
        "    self.device=device\n",
        "    self.start=start\n",
        "    self.decay=decay\n",
        "    self.end=end\n",
        "  def get_action(self,policy,state,step):\n",
        "    self.cur_step=step\n",
        "    ep=self.end+(self.start-self.end) * np.exp(-1*self.cur_step*self.decay)\n",
        "    #self.cur_step=self.cur_step+1\n",
        "    #print(ep,self.cur_step)\n",
        "    if ep>random.random():\n",
        "      #print(\"NO\")\n",
        "      action=random.randrange(self.num)\n",
        "      return action\n",
        "    else:\n",
        "      policy.eval()\n",
        "      with torch.no_grad():\n",
        "        #print(\"yes\")\n",
        "        return torch.argmax(policy.forward(state)).item()\n",
        "  def get_value(self,step):\n",
        "    self.cur_step=step\n",
        "    ep=self.end+(self.start-self.end) * np.exp(-1*self.cur_step*self.decay)\n",
        "    return ep\n",
        "  def greedy(self,policy,state):\n",
        "    policy.eval()\n",
        "    with torch.no_grad():\n",
        "      return torch.argmax(policy.forward(state)).item()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PD3We0fVg26"
      },
      "source": [
        "#This is my convolutional network architecture\n",
        "\n",
        "class convnet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(convnet,self).__init__()\n",
        "    self.conv1= nn.Conv2d(4,32,8)\n",
        "    self.conv2 = nn.Conv2d(32,64,4)\n",
        "    self.conv3=nn.Conv2d(64,64,3)\n",
        "    self.fc1=nn.Linear(64*68*68,512)\n",
        "    self.fc2=nn.Linear(512,64)\n",
        "    self.fc3=nn.Linear(64,2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=F.relu(self.conv1(x))\n",
        "    out=F.relu(self.conv2(out))\n",
        "    out=F.relu(self.conv3(out))\n",
        "    out = out.view(-1,64*68*68)\n",
        "    out=F.relu(self.fc1(out))\n",
        "    out=F.relu(self.fc2(out))\n",
        "    out=self.fc3(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikmS_kL9fzM-"
      },
      "source": [
        "class lin(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(lin,self).__init__()\n",
        "    self.fc1=nn.Linear(2,128)\n",
        "    self.fc2=nn.Linear(128,64)\n",
        "    self.fc3=nn.Linear(64,2)\n",
        "  def forward(self,x):\n",
        "    out=F.relu(self.fc1(x))\n",
        "    out=F.relu(self.fc2(out))\n",
        "    out=self.fc3(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwisq_kgJK3g"
      },
      "source": [
        "# This is the duelling netowork that I wanted to try out, as there are claims that duelling networks works better than double dqn.\n",
        "class duelling(nn.Module):\n",
        "  def __init__(self,num_actions):\n",
        "    super(duelling,self).__init__()\n",
        "    self.a = num_actions\n",
        "    self.conv1 = nn.Conv2d(4,32,8)\n",
        "    self.conv2 =nn.Conv2d(32,64,4)\n",
        "    self.conv3 = nn.Conv2d(64,64,3)\n",
        "    self.fc1_value = nn.Linear(64*68*68,512)\n",
        "    self.fc2_value = nn.Linear(512,64)\n",
        "    self.fc3_value = nn.Linear(64,1)\n",
        "    self.fc1_adv = nn.Linear(64*68*68,512)\n",
        "    self.fc2_adv = nn.Linear(512,64)\n",
        "    self.fc3_adv = nn.Linear(64,self.x)\n",
        "  def forward(self,x):\n",
        "    out=F.relu(self.conv1(x))\n",
        "    out = F.relu(self.conv2(out))\n",
        "    out = F.relu(self.conv3(out))\n",
        "    out = out.view(-1,64*68*68)\n",
        "    state_value = F.relu(self.fc1_value(out))\n",
        "    state_value = F.relu(self.fc2_value(state_value))\n",
        "    state_value = self.fc3_value(state_value)\n",
        "    advantage = F.relu(self.fc1_adv(out))\n",
        "    advantage = F.relu(self.fc2_adv(advantage))\n",
        "    advantage = self.fc3_adv(advantage)\n",
        "\n",
        "    return state_value+advantage-torch.mean(advantage)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA3iVOYIbmMS"
      },
      "source": [
        "#This is the function that I am using to update the target network , soft update\n",
        "\n",
        "def soft_update(local,target,t):\n",
        "  for target_param,local_param in zip(target.parameters(),local.parameters()):\n",
        "    target_param.data.copy_(t*local_param.data+(1-t)*target_param.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuLVQfVrbXC1"
      },
      "source": [
        "#Initialising the target net and policy network and making them start with the same weights for stability reasons\n",
        "\n",
        "target_net = convnet().to(device)\n",
        "policy=convnet().to(device)\n",
        "soft_update(policy,target_net,1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmSFAB_HcLUs"
      },
      "source": [
        "num_episodes=1000000\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf0d1VtZR45N"
      },
      "source": [
        "#converting the image frames by doing pre processing.\n",
        "\n",
        "def convert1(observation):\n",
        "  cv2_imshow(np.array(observation))\n",
        "  ob=torch.tensor(observation)\n",
        "  ob=ob.view(4,80,160)\n",
        "  ob=ob.numpy()\n",
        "\n",
        "  f_ob=[]\n",
        "  for i in range(4):\n",
        "    l=ob[i]\n",
        "    cv2_imshow(l)\n",
        "    print(\"wtf\")\n",
        "    im = Image.fromarray(l)\n",
        "\n",
        "    f_ob.append(np.asarray(im.resize((80,80))))\n",
        "\n",
        "  f_ob=np.array(f_ob)\n",
        "\n",
        "  ob=torch.tensor([f_ob]).to(torch.float)\n",
        "  ob=ob.view(-1,4,80,80)\n",
        "  return ob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp9VzepzWgCn"
      },
      "source": [
        "#initialising memory replay with 10000 capacity\n",
        "mem=replaymemory(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzSoL5Q6pff4"
      },
      "source": [
        "from PIL import Image\n",
        "def convert(observation):\n",
        "  ob=np.array(observation,dtype=\"float32\")\n",
        "  #print(ob.shape)\n",
        "\n",
        "  ob=cv2.cvtColor(ob,cv2.COLOR_BGR2GRAY)\n",
        "  im = Image.fromarray(ob)\n",
        "  ob = np.asarray(im.resize((80,80)))\n",
        "\n",
        "\n",
        "  return ob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnnILOBfd-iv",
        "outputId": "c28ef0c7-2de2-42f6-9089-9c7b54f64a92"
      },
      "source": [
        "#Creating and intialising the gym environment and pushing the first 4 frames into the stack and initialising other parameters required.\n",
        "env = gym.make('ChromeDino-v0')\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "ob=env.reset()\n",
        "done_1=False\n",
        "ob=convert(ob)\n",
        "\n",
        "print(ob.shape)\n",
        "stack=cstate(4)\n",
        "\n",
        "stack.push(ob)\n",
        "stack.push(ob)\n",
        "stack.push(ob)\n",
        "stack.push(ob)\n",
        "\n",
        "a2=torch.tensor([stack.states])\n",
        "\n",
        "a= nn.Conv2d(4,32,8)\n",
        "b = nn.Conv2d(32,64,4)\n",
        "c=nn.Conv2d(64,64,3)\n",
        "out=a(a2)\n",
        "out=b(torch.tensor(out))\n",
        "out=c(torch.tensor(out))\n",
        "print(out.shape)\n",
        "#env=env.unwrapped\n",
        "state=env.reset()\n",
        "reward_sum=0\n",
        "gamma=torch.tensor(0.999)\n",
        "\n",
        "start=1\n",
        "end=0.00001\n",
        "decay=0.1\n",
        "#decay=0.1\n",
        "\n",
        "#tau for soft update\n",
        "\n",
        "tau=0.89\n",
        "\n",
        "t_decay=eps_strat(2,0.9,0.01,0.001,device)\n",
        "print(tau)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 80)\n",
            "torch.Size([1, 64, 68, 68])\n",
            "0.89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvrx1bPnywVL",
        "outputId": "5ce53875-7099-4301-9c1d-dcea04379f39"
      },
      "source": [
        "FILE='/content/drive/MyDrive/chrome_dino/target_net_dino_3.pth'\n",
        "File='/content/drive/MyDrive/chrome_dino/model_dino_3.pth'\n",
        "from IPython.display import clear_output\n",
        "#model.load_state_dict(torch.load(file_path))\n",
        "target_net.load_state_dict(torch.load(FILE))\n",
        "policy.load_state_dict(torch.load(File))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwkhNoEPvCnt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81rvjChAd2j6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "outputId": "4e073073-7b43-40cf-8afd-8820cb8f5e86"
      },
      "source": [
        "import cv2\n",
        "height=720\n",
        "width=1200\n",
        "fps=10\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Setting up video encoding format\n",
        "\n",
        "FILE='/content/drive/MyDrive/chrome_dino/target_net_dino_5.pth'  # File path for saving target network\n",
        "File='/content/drive/MyDrive/chrome_dino/model_dino_5.pth'       # File path for saving policy network\n",
        "step=0\n",
        "step_1=0\n",
        "eps=0\n",
        "lo=[]  # list to store loss values for plotting\n",
        "re=[]  # list to store rewards for plotting\n",
        "video=[]\n",
        "video_ep=[]  # List to store video frames for the current episode\n",
        "max_rew=0  # keeping track track of the max reward\n",
        "\n",
        "for eps in range(num_episodes):  # Training loop over a specified number of episodes\n",
        "\n",
        "    reward_sum=0  # initi total reward for the current episode\n",
        "    state=env.reset()  # Reseteting the environment\n",
        "    state=convert(state)\n",
        "\n",
        "    done_1=False  # flag to check if the current episode is done\n",
        "    video_ep=[]\n",
        "    while not done_1:  # Loop until the episode ends\n",
        "        step=step+1\n",
        "        ep=eps_strat(2, start, decay, end, device)  # Create epsilon-greedy strategy for exploration-exploitation\n",
        "\n",
        "        # Get the current state stack and reshape it for the network\n",
        "        a2=torch.tensor(stack.states)\n",
        "        a2=a2.view(1,4,80,80)\n",
        "        action= ep.get_action(policy, a2.float().to(device), step)  # Select an action based on epsilon-greedy policy\n",
        "\n",
        "        next_state, reward, done_1, info = env.step(action)  # Take the action in the environment\n",
        "        video_ep.append(next_state)  # Add frame to current episode video frames\n",
        "\n",
        "        next_state=convert(next_state)\n",
        "        stack.push(next_state)  # Push the new state onto the state stack\n",
        "        a3=torch.tensor(stack.states)\n",
        "        a3=a3.view(1,4,80,80)\n",
        "\n",
        "        reward = 1\n",
        "\n",
        "        if done_1:\n",
        "            reward = -10  # Setting reward to -10 for game over, as the agent died\n",
        "\n",
        "        # storing the experience in the replay memory\n",
        "        e1 = Experience(a2.numpy(), action, a3.numpy(), reward, done_1)\n",
        "        mem.push(e1)\n",
        "\n",
        "        reward_sum += reward  # accumulate the rewards for this episode\n",
        "        state = next_state  #update to nest state\n",
        "\n",
        "    if max_rew < reward_sum:\n",
        "        max_rew = reward_sum\n",
        "        video = video_ep.copy()\n",
        "\n",
        "    re.append(reward_sum)  # Track rewards for plotting\n",
        "    print(eps, reward_sum)\n",
        "\n",
        "    if mem.can_provide(64):  # If enough experiences are in the replay buffer, start training\n",
        "        epochs = 10\n",
        "        for i in range(epochs):\n",
        "            states_1, actions, next_states, rewards, done = mem.sample(64)  # Sample a mini-batch of experiences\n",
        "\n",
        "            # Reshape the sampled states for the network\n",
        "            states_1 = states_1.view(64, 4, 80, 80)\n",
        "            next_states = next_states.view(64, 4, 80, 80)\n",
        "\n",
        "            # Calculate the expected Q values using the policy network\n",
        "            ex = policy.forward(next_states.float()).detach().cpu().numpy().tolist()\n",
        "            target_q = target_net.forward(next_states.float()).detach().cpu().numpy()\n",
        "            j = [t.index(max(t)) for t in ex]  # Get the action indices with the highest Q-values\n",
        "\n",
        "            # Select the target Q-values corresponding to the best actions\n",
        "            target_q = torch.tensor([target_q[i][j[i]] for i in range(len(j))]).to(device).detach()\n",
        "\n",
        "            done = done.int().to(device)\n",
        "            q = (rewards + gamma * (target_q * (1 - done))).detach()  # Calculate the target Q-values\n",
        "            q = q.unsqueeze(1)\n",
        "            l = torch.tensor([actions[i] for i in range(64)]).to(device)\n",
        "            l = l.unsqueeze(1)\n",
        "\n",
        "            # Calculate the loss between the predicted Q-values and the target Q-values\n",
        "            exp_q = policy.forward(states_1.float()).gather(-1, l)\n",
        "            loss = nn.MSELoss()\n",
        "            tr = loss(exp_q, q)\n",
        "            lo.append(tr)  # Track loss for plotting\n",
        "\n",
        "            # Perform a gradient descent step\n",
        "            optimizer = torch.optim.Adam(policy.parameters(), lr=alpha)\n",
        "            optimizer.zero_grad()\n",
        "            tr.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    if eps % 100 == 0:  # Every 100 episodes, update the target network and plot training metrics\n",
        "        soft_update(policy, target_net, 1)\n",
        "        episodes = range(len(lo))\n",
        "        epi = range(len(re))\n",
        "        plt.plot(episodes, lo, 'g', label='loss')\n",
        "        plt.xlabel('episodes')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        plt.plot(epi, re, 'g', label='rewards')\n",
        "        plt.xlabel('episodes')\n",
        "        plt.ylabel('rewards')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    if eps % 50 == 0:  # Save the model weights and best video frames every 50 episodes\n",
        "        torch.save(target_net.state_dict(), FILE)\n",
        "        torch.save(policy.state_dict(), File)\n",
        "        print(\"Weights saved\")\n",
        "        np.save('dino', np.array(video))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Weights saved\n",
            "1 3115\n",
            "2 319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-ae600cf9c877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m#print(action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;31m#cv2_imshow(next_state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#time.sleep(0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym_chrome_dino/envs/chrome_dino_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpress_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgametime_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym_chrome_dino/envs/chrome_dino_env.py\u001b[0m in \u001b[0;36m_observe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgba2rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym_chrome_dino/utils/helpers.py\u001b[0m in \u001b[0;36mrgba2rgb\u001b[0;34m(im)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fill background as white color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 3 is the alpha channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2192\u001b[0m         \"\"\"\n\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbands\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[0mims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadonly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exclusive_fp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_exclusive_fp_after_loading\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36mload_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%r %s %s (unknown)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_animated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ocQIkIX_IXV"
      },
      "source": [
        "for i in video:\n",
        "  cv2_imshow(i)\n",
        "  time.sleep(0.07)\n",
        "  clear_output()\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "lenNqWSpe2_I",
        "outputId": "72b8b883-d721-4dcf-8498-a3b27da1f547"
      },
      "source": [
        "for ep in range(num_episodes): yo yo for you\n",
        "  reward_sum=0\n",
        "  htyuukhj=8\n",
        "  state=env.reset()\n",
        "  done_1=False\n",
        "  while not done_1:\n",
        "\n",
        "    ep=eps_strat(2,start,decay,end,device)\n",
        "    action= ep.get_action(policy,state)\n",
        "    next_state,reward,done_1,info=env.step(action)\n",
        "\n",
        "\n",
        "    if done_1==True:\n",
        "      reward=-10\n",
        "    else:\n",
        "      reward=1\n",
        "    e1=Experience(state,action,next_state,reward,done_1)\n",
        "    #print(type(e1.state))\n",
        "    mem.push(e1)\n",
        "    reward_sum+=reward\n",
        "    state=next_state\n",
        "    #print(reward)\n",
        "  If reward_sum>300\n",
        "  print(ep,reward_sum)\n",
        "\n",
        "  if(mem.can_provide(512)):\n",
        "    states,actions,next_states,rewards,done=mem.sample(512)\n",
        "    target_q=target_net.forward(next_states.float()).detach()\n",
        "    target_q=torch.tensor([max(t) for t in target_q]).to(device)\n",
        "\n",
        "    done=done.int().to(device)\n",
        "\n",
        "    q=rewards+gamma*(target_q*(1-done))\n",
        "    #print(gamma*(target_q*(1-done)))\n",
        "    exp_q=target_net.forward(states.float())\n",
        "    exp_q=torch.tensor([exp_q[i][actions[i]] for i in range(10)],requires_grad=True).to(device)\n",
        "    #loss function\n",
        "    loss=nn.MSELoss()\n",
        "    tr=loss(q,exp_q)\n",
        "    tr.backward()\n",
        "    # optimizer\n",
        "    optimizer= torch.optim.SGD(policy.parameters(),lr=alpha)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-4c401b2fd931>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    If reward_sum>300\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTgsecHt0FjX"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAGjWUwwesYU"
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruEk2esH0JAd"
      },
      "source": [
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMKQHchN0OWj",
        "outputId": "aa2591f6-c44c-49de-a73d-26475ab2785b"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fab1d6e81d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}